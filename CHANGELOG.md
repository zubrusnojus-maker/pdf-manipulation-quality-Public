# Changelog

All notable changes to the PDF Toolkit project are documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [Unreleased]

### Added

- Comprehensive test suite improvements with better coverage
- New documentation files: `MIGRATION_GUIDE.md`, `CHANGELOG.md`, improved `README.md`
- Enhanced code documentation and inline comments
- Additional usage examples in docs

### Changed

- Updated test fixtures and test data management
- Improved error handling in core modules
- Code style consistency improvements across the codebase
- Updated dependencies to latest stable versions

### Fixed

- Test compatibility issues with latest pytest version
- Path handling edge cases in Windows environments
- Minor bugs in PII detection regex patterns

## [1.0.0] - 2025-11

### Added

#### Package Structure

- Reorganized codebase into proper Python package structure (`src/pdf_toolkit/`)
- Created modular architecture with clear separation of concerns:
  - `core/` - Core processing logic (processor, layout, constants)
  - `models/` - Model loading and management
  - `redaction/` - PII detection and redaction
  - `utils/` - Utility functions (PDF operations)
  - `cli/` - Command-line interfaces
- Package installable via `pip install -e .`
- Proper `__init__.py` exports for clean public API

#### Command-Line Tools

- `pdf-process` command for PDF OCR and text manipulation
- `pdf-redact` command for PII detection and redaction
- Commands available system-wide after package installation
- Comprehensive CLI help documentation

#### MCP (Model Context Protocol) Integration

- Full MCP server implementation using FastMCP
- Four main tools exposed via MCP:
  - `redact_pdf` - Redact sensitive information from PDFs
  - `detect_pii` - Detect PII in text
  - `process_pdf` - OCR and text manipulation
  - `optimize_pdf_file` - Optimize PDF file size
- MCP server module: `src/pdf_toolkit/mcp_server.py`
- Integration with AI assistants (Claude Desktop, etc.)

#### HuggingFace Space Deployment

- Gradio web interface (`app.py`) with four main tabs:
  - PII Detection
  - Text Redaction
  - PDF Text Extraction
  - PDF Redaction
- MCP server functionality in Gradio app (`mcp_server=True`)
- Ready-to-deploy HuggingFace Space with proper metadata
- Requirements file for HuggingFace: `requirements-hf.txt`
- Professional README for HuggingFace: `README_HF.md`

#### Documentation

- `docs/PDF_PROCESSING_README.md` - Comprehensive processing guide
- `docs/QUICK_REFERENCE.md` - Quick start and commands
- `docs/MODEL_COMPARISON.md` - Detailed model benchmarks
- `CLAUDE.md` - Developer guide for Claude Code
- `README_HF.md` - HuggingFace Space documentation
- Code examples for all major features
- Architecture diagrams and explanations

#### Testing Infrastructure

- Pytest configuration in `pytest.ini` and `pyproject.toml`
- Test suite covering:
  - `test_pdf_processor.py` - Core processing logic
  - `test_pdf_redactor.py` - PII detection/redaction
  - `test_pdf_redactor_integration.py` - End-to-end tests
  - `test_quick_pdf_process.py` - Quick processing script
  - `test_sample.py` - Basic smoke tests
- Test fixtures and sample data management
- Coverage reporting configuration

### Changed

#### Code Organization

- Refactored monolithic scripts into modular components
- Created `ModelLoader` class for centralized model management
- Separated concerns: processing, redaction, layout analysis
- Consistent coding style across all modules
- Improved error handling and logging

#### Legacy Compatibility

- Root-level `pdf_processor.py` now imports from package
- Root-level `pdf_redactor.py` now imports from package
- `quick_pdf_process.py` maintained for simple use cases
- All legacy imports continue to work (deprecated)

#### Model Management

- Centralized model loading in `ModelLoader` class
- Better device management (GPU/CPU auto-detection)
- Optimized memory usage for large models
- Clear model size tiers: small (Mistral-7B), large (Llama-2-13B)

#### PDF Processing

- Enhanced layout analysis integration
- Improved text insertion with layout-aware formatting
- Better handling of complex document structures
- Optimized rasterization performance

#### PII Redaction

- More comprehensive regex patterns in `patterns.py`
- Better detection accuracy for UK-specific data formats
- Configurable date preservation
- Detailed statistics and reporting

### Deprecated

- Direct imports from root-level scripts (`pdf_processor.py`, `pdf_redactor.py`)
- Use package imports instead: `from pdf_toolkit import PDFProcessor`
- Legacy wrappers will be removed in v2.0

### Fixed

- Path handling issues on Windows
- Model caching and download reliability
- Memory leaks in long-running processes
- Edge cases in text extraction and reinsertion

## [0.9.0] - 2024-11

### Added

- Initial implementation of quality-focused PDF processing
- TrOCR Large model integration for high-accuracy OCR
- Mistral-7B-Instruct and Llama-2-13B-Chat text processing
- LayoutLMv3 for document structure analysis
- PII detection and redaction capabilities
- Support for monetary amounts, dates, postcodes, names

### Features

- PDF to image rasterization with configurable DPI
- Text summarization and rewriting operations
- Table and header detection
- Layout-aware text reinsertion
- PyMuPDF-based PDF manipulation
- pikepdf optimization support

## [0.1.0] - 2024-09

### Added

- Basic PDF processing proof of concept
- Simple OCR with base models
- Monolithic script structure
- Manual model management
- Basic text extraction and manipulation

---

## Version Comparison

| Version | Architecture | Models | Deployment | Notable Features |
|---------|-------------|--------|------------|-----------------|
| **1.0.0** | Modular package | TrOCR Large, Mistral/Llama, LayoutLMv3 | Local, HF Space, MCP | Package install, CLI, MCP |
| 0.9.0 | Monolithic scripts | TrOCR Large, Mistral/Llama | Local only | Quality-focused processing |
| 0.1.0 | Single script | Basic models | Local only | Proof of concept |

## Quality Tiers Across Versions

### v1.0.0 Quality Levels

| Tier | Model | VRAM | Quality Score | Speed | Use Case |
|------|-------|------|---------------|-------|----------|
| High | Llama-2-13B | 16GB | 9.2/10 | ~5 pages/min | Legal, medical, research |
| Balanced | Mistral-7B | 8GB | 8.7/10 | ~10 pages/min | Business documents (default) |
| Fast | BART-Large | 3GB | 7.1/10 | ~25 pages/min | High-volume processing |

### v0.9.0 Quality

- Single tier: Llama-2-13B only (9.2/10)
- No flexible model selection
- Higher resource requirements

### v0.1.0 Quality

- Basic OCR and text processing (~6.5/10)
- Limited accuracy
- No layout analysis

## Migration Paths

### From v0.9.0 to v1.0.0

**Required changes:**

1. Install package: `pip install -e .`
2. Update imports: `from pdf_toolkit import PDFProcessor`
3. Use CLI commands: `pdf-process` instead of `python pdf_processor.py`

**Optional upgrades:**

- Enable MCP server for AI assistant integration
- Deploy to HuggingFace Space for web access
- Use layout analysis for better quality

See `MIGRATION_GUIDE.md` for detailed instructions.

### From v0.1.0 to v1.0.0

**Complete rewrite recommended:**

- New API and architecture
- Different model requirements
- Vastly improved quality and features

## Breaking Changes

### v1.0.0

- None (fully backwards compatible with v0.9.0)
- Legacy wrappers maintained for compatibility
- All old code continues to work

### v0.9.0 â†’ v0.1.0

- Complete API change
- Model requirements significantly increased
- Script structure fundamentally different

## Upgrade Notes

### Upgrading to v1.0.0

**Immediate benefits:**

- No code changes required (uses legacy wrappers)
- Optional: migrate to package imports for cleaner code
- Optional: use CLI commands for convenience
- Optional: enable MCP integration

**To unlock new features:**

```bash
# Install package
pip install -e .

# Update code
# OLD: from pdf_processor import PDFProcessor
# NEW: from pdf_toolkit import PDFProcessor

# Use CLI
pdf-process document.pdf --model-size large

# Enable MCP
python -m pdf_toolkit.mcp_server
```

## Known Issues

### v1.0.0

- Large model (Llama-2-13B) requires 16GB VRAM
- First run downloads ~30GB of models
- Windows path handling needs `poppler-utils` manual installation

### Planned Fixes

- Model quantization for lower VRAM usage (v1.1)
- Incremental model downloads with progress bars (v1.1)
- Windows installer with bundled dependencies (v1.2)

## Future Roadmap

### v1.1.0 (Planned Q1 2026)

- Model quantization support (4-bit, 8-bit)
- Batch processing API
- Progress callbacks and streaming output
- Deprecation warnings for legacy imports
- Performance optimizations

### v1.2.0 (Planned Q2 2026)

- Additional language support beyond English
- Custom model support
- PDF form field detection and processing
- Enhanced table extraction
- Cloud deployment templates (Docker, AWS Lambda)

### v2.0.0 (Planned Q3 2026)

- Remove legacy wrapper support
- Python 3.12+ minimum requirement
- Async/await API
- Plugin system for custom processing
- Web UI improvements
- Multi-language OCR

## Security

### v1.0.0 Security Features

- PII detection for data protection
- Redaction with consistent mapping
- Local model execution (no data sent to cloud)
- Audit trail with mapping files

### Security Advisories

- None currently

## Contributors

Thanks to all contributors who made v1.0.0 possible:

- Package structure modernization
- MCP integration implementation
- HuggingFace Space deployment
- Comprehensive documentation
- Testing infrastructure

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

**Last Updated:** November 30, 2025

For migration assistance, see [MIGRATION_GUIDE.md](MIGRATION_GUIDE.md).
